{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o9pGTFnhuAaL"
   },
   "source": [
    "# **Detection Rule Analyzer for Google Chronicle SIEM**\n",
    "In order to get useful information from detection rules, their documentation must be up-to-date and brilliantly documented. This notebook connects to Chronicle SIEM through its API, grabs the detection rules, and analyzes them to check their documentation.\n",
    "\n",
    "Detection rules in Chronicle SIEM are written in [YARA-L](https://cloud.google.com/chronicle/docs/detection/yara-l-2-0-overview) üîó format and the section `meta` aggregates the documentation fields for them. For the purpose of this notebook, the following rules apply for such fields --all case-sensitive:\n",
    "\n",
    "- `author`: String up to 35 characters.\n",
    "- `description`: String up to 140 characters.\n",
    "- `reference`: URL (string).\n",
    "- `response`: URL (string).\n",
    "- `priority`: String in [`Low`, `Medium`, `High`].\n",
    "- `severity`: String in [`Low`, `Medium`, `High`].\n",
    "- `detection_score`: String in [`Basic`, `Fair`, `Good`, `Very Good`, `Excellent`].\n",
    "- `mitre_technique`: MITRE Techniques list:\n",
    "  - `T8888`\n",
    "  - `T8888.888`\n",
    "  - `T8888,T8889,T8890`\n",
    "  - `T8888,T8888.888,T8889`\n",
    "\n",
    "Additionally, the name of the rule is tracked by this notebook and it's expectected that it is made of lowercase characters, written in snake_case format, and up to 70 characters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e_I6_lJeAWp_"
   },
   "source": [
    "---\n",
    "## **Part 1. Rules Retrieval**\n",
    "The first step is to log into Chronicle SIEM's API and get the latest detection rules created there. The routines in this section will handle that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "3YNH6ePJA5ox"
   },
   "outputs": [],
   "source": [
    "#@title Step 1a. Keyfile Upload and Client Initialization\n",
    "#@markdown Upload a valid keyfile for Chronicle SIEM to allow the login.\n",
    "#@markdown If it's OK, a new session will be raised and attached to a client.\n",
    "\n",
    "from os import rename\n",
    "from json import JSONDecodeError\n",
    "\n",
    "from google.colab import files\n",
    "from google.oauth2 import service_account\n",
    "from google.auth.transport.requests import AuthorizedSession\n",
    "from googleapiclient import _auth\n",
    "\n",
    "KEYFILE = 'chronicle.key'\n",
    "\n",
    "print('Select and upload the Chronicle\\'s keyfile')\n",
    "uploaded = files.upload()\n",
    "rename(list(uploaded.keys())[0], f'{KEYFILE}')\n",
    "print('üü¢ Keyfile uploaded successfuly')\n",
    "\n",
    "def init_webclient(keyfile, region=\"North America\"):\n",
    "  SCOPES = [\n",
    "      'https://www.googleapis.com/auth/chronicle-backstory',  # regular backstory API\n",
    "      'https://www.googleapis.com/auth/malachite-ingestion',  # ingestion API\n",
    "      'https://www.googleapis.com/auth/cloud-platform'        # dataplane API (experimenting)\n",
    "  ]\n",
    "\n",
    "  if region == 'North America': region_prefix = ''; cbn_region = 'US'; cli_region = 'US'\n",
    "  elif region == 'Europe': region_prefix = 'europe-'; cbn_region = 'EUROPE'; cli_region = 'EUROPE'\n",
    "  elif region == 'United Kingdom': region_prefix = 'europe-west2-'; cbn_region = 'EUROPE'; cli_region = 'EUROPE-WEST2'\n",
    "  elif region == 'Asia (Singapore)': region_prefix = 'asia-southeast1-'; cbn_region = 'ASIA'; cli_region = 'ASIA-SOUTHEAST1'\n",
    "  elif region == 'Australia (Sydney)': region_prefix = 'australia-southeast1-'; cbn_region = 'AUSTRALIA'; cli_region = 'AUSTRALIA-SOUTHEAST1'\n",
    "  elif region == 'Tel Aviv': region_prefix = 'me-west1-'; cbn_region = 'AUSTRALIA'; cli_region = 'ME-WEST1'\n",
    "\n",
    "  try:\n",
    "    credentials = service_account.Credentials.from_service_account_file(keyfile, scopes=SCOPES)\n",
    "  except JSONDecodeError:\n",
    "    raise Exception('üî¥ File not in JSON format')\n",
    "  except ValueError:\n",
    "    raise Exception('üî¥ Invalid key')\n",
    "\n",
    "  http_client = _auth.authorized_http(credentials)\n",
    "  session = AuthorizedSession(credentials)\n",
    "  return (http_client, session, region_prefix, cbn_region, cli_region)\n",
    "\n",
    "http_client, session, region_prefix, cbn_region, cli_region = init_webclient(KEYFILE)\n",
    "print('üü¢ Webclient initialized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "hjYoN90wEoUo"
   },
   "outputs": [],
   "source": [
    "#@title Step 1b. Rule Load and Sanity Check\n",
    "#@markdown This routine will effectively connect to Chronicle SIEM, get the Detection Rules, and load them into a Pandas dataframe. üêºüêº\n",
    "#@markdown It'll also run sanity checks to find missing fields and fields out of the norm.\n",
    "\n",
    "from urllib.parse import urlencode, urlparse\n",
    "from http import HTTPStatus\n",
    "from json import loads\n",
    "from base64 import b64encode, b64decode\n",
    "from re import compile\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "XS_STRING = 35\n",
    "S_STRING  = 70\n",
    "M_STRING  = 140\n",
    "L_STRING  = 240\n",
    "\n",
    "SCORES_1 = ['low', 'medium', 'high']\n",
    "SCORES_2 = ['basic', 'fair', 'good', 'very good', 'excellent']\n",
    "\n",
    "RE_NAME = compile(r'^[a-z0-9_]{3,70}$')\n",
    "RE_TECHNIQUES = compile(r'^T\\d{4}(\\.\\d{3})?(,\\s*T\\d{4}(\\.\\d{3})?)*$')\n",
    "\n",
    "\n",
    "def request(http_client, region_prefix, page_size=2000, page_token=''):\n",
    "  url_params = {'page_size': page_size}\n",
    "  if page_token:\n",
    "    url_params['page_token'] = page_token\n",
    "  uri = f'https://{region_prefix}backstory.googleapis.com/v2/detect/rules?{urlencode(url_params)}'\n",
    "  res = http_client.request(uri, 'GET')\n",
    "  if res[0].status == HTTPStatus.OK:\n",
    "    return loads(res[1])\n",
    "  else:\n",
    "    return loads(res[1]).get('error').get('message')\n",
    "\n",
    "def check_name(s):\n",
    "  if RE_NAME.search(s):\n",
    "    return s\n",
    "  else:\n",
    "    return None\n",
    "\n",
    "def check_alerting_live(s):\n",
    "  if s:\n",
    "    return True\n",
    "  else:\n",
    "    return False\n",
    "\n",
    "def check_author(s):\n",
    "  if len(s) <= XS_STRING:\n",
    "    return s\n",
    "  else:\n",
    "    return None\n",
    "\n",
    "def check_url(s):\n",
    "  try:\n",
    "    url = urlparse(s)\n",
    "    if all([url.scheme, url.netloc]):\n",
    "      return s\n",
    "    else:\n",
    "      return None\n",
    "  except TypeError:\n",
    "    return None\n",
    "\n",
    "def check_priority_severity(s):\n",
    "  try:\n",
    "    s = s.lower()\n",
    "    if s in SCORES_1:\n",
    "      return s\n",
    "    else:\n",
    "      return None\n",
    "  except AttributeError:\n",
    "    return None\n",
    "\n",
    "def check_techniques(s):\n",
    "  try:\n",
    "    if RE_TECHNIQUES.search(s):\n",
    "      return s.replace(' ','').split(',')\n",
    "    else:\n",
    "      return None\n",
    "  except TypeError:\n",
    "    return None\n",
    "\n",
    "def check_detection_score(s):\n",
    "  try:\n",
    "    s = s.lower()\n",
    "    if s in SCORES_2:\n",
    "      return s\n",
    "    else:\n",
    "      return None\n",
    "  except AttributeError:\n",
    "    return None\n",
    "\n",
    "def check_description(s):\n",
    "  try:\n",
    "    if len(s) <= M_STRING:\n",
    "      return s\n",
    "    else:\n",
    "      return None\n",
    "  except TypeError:\n",
    "    return None\n",
    "\n",
    "\n",
    "fields = [\n",
    "  'id',                        # ruleId\n",
    "  'version',                   # versionId\n",
    "  'name',                      # ruleName\n",
    "  'content',                   # ruleText\n",
    "  'alerting',                  # alertingEnabled\n",
    "  'live',                      # liveRuleEnabled\n",
    "  'version_date',              # versionCreateTime\n",
    "  'compilation',               # compilationState\n",
    "  'type',                      # ruleType\n",
    "  'meta.author',               # metadata.author\n",
    "  'meta.priority',             # metadata.priority\n",
    "  'meta.severity',             # metadata.severity\n",
    "  'meta.mitre_technique',      # metadata.mitre_technique\n",
    "  'meta.detection_score',      # metadata.detection_score\n",
    "  'meta.description',          # metadata.description\n",
    "  'meta.reference',            # metadata.reference\n",
    "  'meta.response'              # metadata.response\n",
    "]\n",
    "manual_fields = ['name', 'meta.author', 'meta.priority',\n",
    "                 'meta.severity', 'meta.mitre_technique',\n",
    "                 'meta.detection_score', 'meta.description',\n",
    "                 'meta.reference', 'meta.response']\n",
    "\n",
    "in_rules = request(http_client, region_prefix)\n",
    "print(f'üü¢ {len(in_rules[\"rules\"])} rules retrieved from Chronicle')\n",
    "\n",
    "out_rules = list()\n",
    "errors = pd.DataFrame(columns=['id','name','error'])\n",
    "\n",
    "for rule in in_rules['rules']:\n",
    "  data = {\n",
    "    'id': rule['ruleId'],\n",
    "    'name': rule['ruleName'],\n",
    "    'version': rule['versionId'],\n",
    "    'content': b64encode(rule['ruleText'].encode()).decode(),\n",
    "    'version_date': rule['versionCreateTime'],\n",
    "    'compilation': rule['compilationState'],\n",
    "    'type': rule['ruleType']\n",
    "  }\n",
    "\n",
    "  try: data['alerting'] = rule['alertingEnabled']\n",
    "  except KeyError: data['alerting'] = None\n",
    "\n",
    "  try: data['live'] = rule['liveRuleEnabled']\n",
    "  except KeyError: data['live'] = None\n",
    "\n",
    "  try: data['meta.author'] = rule['metadata']['author']\n",
    "  except KeyError: data['author'] = None\n",
    "\n",
    "  try: data['meta.priority'] = rule['metadata']['priority']\n",
    "  except KeyError: data['meta.priority'] = None\n",
    "\n",
    "  try: data['meta.severity'] = rule['metadata']['severity']\n",
    "  except KeyError: data['meta.severity'] = None\n",
    "\n",
    "  try: data['meta.mitre_technique'] = rule['metadata']['mitre_technique']\n",
    "  except KeyError: data['meta.mitre_technique'] = None\n",
    "\n",
    "  try: data['meta.detection_score'] = rule['metadata']['detection_score']\n",
    "  except KeyError: data['meta.detection_score'] = None\n",
    "\n",
    "  try: data['meta.description'] = rule['metadata']['description']\n",
    "  except KeyError: data['meta.description'] = None\n",
    "\n",
    "  try: data['meta.reference'] = rule['metadata']['reference']\n",
    "  except KeyError: data['meta.reference'] = None\n",
    "\n",
    "  try: data['meta.response'] = rule['metadata']['response']\n",
    "  except KeyError: data['meta.response'] = None\n",
    "\n",
    "  out_rules.append(data)\n",
    "\n",
    "rules = pd.DataFrame(out_rules)\n",
    "rules.insert(len(rules.columns)-1, 'content', rules.pop('content'))  # content as last column\n",
    "rules['name'] = rules['name'].apply(check_name)\n",
    "rules['version_date'] = rules['version_date'].apply(pd.to_datetime)\n",
    "rules['alerting'] = rules['alerting'].apply(check_alerting_live)\n",
    "rules['live'] = rules['live'].apply(check_alerting_live)\n",
    "rules['meta.author'] = rules['meta.author'].apply(check_author)\n",
    "rules['meta.priority'] = rules['meta.priority'].apply(check_priority_severity)\n",
    "rules['meta.severity'] = rules['meta.severity'].apply(check_priority_severity)\n",
    "rules['meta.mitre_technique'] = rules['meta.mitre_technique'].apply(check_techniques)\n",
    "rules['meta.detection_score'] = rules['meta.detection_score'].apply(check_detection_score)\n",
    "rules['meta.description'] = rules['meta.description'].apply(check_description)\n",
    "rules['meta.reference'] = rules['meta.reference'].apply(check_url)\n",
    "rules['meta.response'] = rules['meta.response'].apply(check_url)\n",
    "\n",
    "# catching up errors\n",
    "for field in manual_fields:\n",
    "  aux = rules[rules[field].isnull()][['id','name']]\n",
    "  aux['error'] = f'{field} not found or out of the norm'\n",
    "  errors = pd.concat([errors, aux])\n",
    "errors = errors.sort_values(by=['name']).drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "print(f'üü¢ rules loaded into üêºüêºüêº dataframe ({rules.shape[0]} rows x {rules.shape[1]} columns)')\n",
    "print(f'üî¥ {errors.shape[0]} syntax errors found')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "Gls41tQkuTZM"
   },
   "outputs": [],
   "source": [
    "#@title Step 1c. [Optional] Dataframe Troubleshoot\n",
    "#@markdown This subsection is meant only for troubleshooting reasons. If you wanna see the dataframe resulting from the Chronicle import, run it. If not, you can skip it.\n",
    "\n",
    "#@markdown If you run it with `show_rules == True`, then you'll see the rules' dataframe, if it is `False`, you'll see the errors' dataframe.\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "\n",
    "show_rules = False #@param['True','False']{type:\"raw\"}\n",
    "\n",
    "if show_rules:\n",
    "  display(rules)\n",
    "else:\n",
    "  display(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "oVQMbJvdLfNi"
   },
   "outputs": [],
   "source": [
    "#@title Step 1d. [Optional] Rule Visualization\n",
    "#@markdown Decodes a rule from the data frame (column `content`) so you can see its code.\n",
    "\n",
    "encoded_rule = ''  #@param{type:\"string\"}\n",
    "decoded_rule = b64decode(encoded_rule)\n",
    "print(decoded_rule.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rrUUhz9kEBET"
   },
   "source": [
    "---\n",
    "## **Part 2. Rules Analysis**\n",
    "With all rules in the dataframe, we will analyze if their fields are following the standards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "-3MNz3XgYjWQ"
   },
   "outputs": [],
   "source": [
    "#@title Step 2a. Chart Setup\n",
    "#@markdown This snipet imports libraries needed to deal with charts and sets up the style.\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "# full list in matplotlib.style.available\n",
    "style = 'grayscale'  #@param['Solarize_Light2', '_classic_test_patch', '_mpl-gallery', '_mpl-gallery-nogrid', 'bmh', 'classic', 'dark_background', 'fast', 'fivethirtyeight', 'ggplot', 'grayscale', 'seaborn-v0_8', 'seaborn-v0_8-bright', 'seaborn-v0_8-colorblind', 'seaborn-v0_8-dark', 'seaborn-v0_8-dark-palette', 'seaborn-v0_8-darkgrid', 'seaborn-v0_8-deep', 'seaborn-v0_8-muted', 'seaborn-v0_8-notebook', 'seaborn-v0_8-paper', 'seaborn-v0_8-pastel', 'seaborn-v0_8-poster', 'seaborn-v0_8-talk', 'seaborn-v0_8-ticks', 'seaborn-v0_8-white', 'seaborn-v0_8-whitegrid', 'tableau-colorblind10']\n",
    "plt.style.use(style)\n",
    "\n",
    "print(f'üü¢ Setup done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "1cfWzPmUEccm"
   },
   "outputs": [],
   "source": [
    "#@title Step 2b. Documentation Analysis\n",
    "#@markdown Some insights on documentation problems.\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "total_rules = len(rules)\n",
    "alerting_rules = len(rules[rules['alerting'] == True])\n",
    "live_rules = len(rules[rules['live'] == True])\n",
    "poorly_documented_rules = len(errors['name'].drop_duplicates())\n",
    "alerting_not_live = len(rules[(rules['alerting'] == True) & (rules['live'] == False)])\n",
    "\n",
    "display(Markdown(f'''\n",
    "# üîã {total_rules} rules in total\n",
    "# üö® {alerting_rules} rules alerting\n",
    "# üîõ {live_rules} live rules\n",
    "# üö© {poorly_documented_rules} rules with documentation issues\n",
    "# üîî {alerting_not_live} rules alerting and not live\n",
    "'''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "i1gD3ZOFaRzM"
   },
   "outputs": [],
   "source": [
    "#@title Step 2c. Priority, Severity, and Detection Score Distribution\n",
    "\n",
    "fig = plt.figure()\n",
    "ax_pri = fig.add_subplot(311)\n",
    "ax_sev = fig.add_subplot(312)\n",
    "ax_sco = fig.add_subplot(313)\n",
    "\n",
    "ax_priorities = rules['meta.priority'].value_counts().plot(kind='barh', ax=ax_pri)\n",
    "# ax_priorities.set_xlabel('Count')\n",
    "ax_priorities.set_ylabel('Priority')\n",
    "\n",
    "ax_severities = rules['meta.severity'].value_counts().plot(kind='barh', ax=ax_sev)\n",
    "# ax_severities.set_xlabel('Count')\n",
    "ax_severities.set_ylabel('Severity')\n",
    "\n",
    "ax_scores = rules['meta.detection_score'].value_counts().plot(kind='barh', ax=ax_sco)\n",
    "ax_scores.set_xlabel('Count')\n",
    "ax_scores.set_ylabel('Detection Score')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "Abh0_oE6qCxK"
   },
   "outputs": [],
   "source": [
    "#@title Step 2d. Word Cloud\n",
    "# Colormap options follow the Matplotlib ones: https://matplotlib.org/stable/users/explain/colors/colormaps.html\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# import urllib.request\n",
    "# urllib.request.urlretrieve(\n",
    "#   'https://domain/path/to/image',\n",
    "#   'nu-cloud.png')\n",
    "\n",
    "\n",
    "# SHAPE = 'wc-shape.png'\n",
    "nu_palette = {\n",
    "    'The Purple': '820AD1FF',\n",
    "    'The Purple Sur Ton': 'AA68FFFF',\n",
    "    'Grey': 'E4E4E4FF',\n",
    "    'Off-White': 'F4F4F4FF',\n",
    "    'White': 'FFFFFFFF',\n",
    "    'Black': '000000FF'\n",
    "}\n",
    "wc_source = 'meta.description'  #@param['meta.description','meta.mitre_technique']\n",
    "# wc_mask = False                     #@param['True','False']{type:'raw'}\n",
    "wc_bg_color = 'Black'               #@param['The Purple','The Purple Sur Ton','Grey','Off-White','White','Black']\n",
    "wc_colormap = 'rainbow'             #@param['Purples','viridis','binary','cool','PRGn','Paired','tab20b','tab20c','rainbow']\n",
    "wc_max_words = 200                  #@param{type:\"slider\",min:20,max:200,step:10}\n",
    "wc_contour_width = 0                #@param{type:\"slider\",min:0,max:10,step:1}\n",
    "wc_dpi = 100                        #@param{type:\"slider\",min:100,max:300,step:100}\n",
    "\n",
    "# if wc_mask:\n",
    "#   wc_mask_shape = np.array(Image.open(SHAPE))\n",
    "# else:\n",
    "#   wc_mask_shape = None\n",
    "wc_stopwords = ['rule', 'rules', 'based', 'detected', 'many', 'someone']\n",
    "\n",
    "wc = WordCloud(\n",
    "    width=1920,\n",
    "    height=1080,\n",
    "    stopwords=wc_stopwords+list(STOPWORDS),\n",
    "    collocations=True,\n",
    "    max_words=wc_max_words,\n",
    "    background_color=f'#{nu_palette[wc_bg_color]}',\n",
    "    colormap=wc_colormap,\n",
    "    # mask=wc_mask_shape,\n",
    "    contour_width=wc_contour_width,\n",
    "    contour_color='#AA68FFFF'\n",
    "    )\n",
    "\n",
    "if wc_source == 'meta.mitre_technique':\n",
    "  wc.generate_from_text(' '.join(rules[rules[wc_source].notnull()][wc_source].sum()))\n",
    "else:\n",
    "  wc.generate_from_text(' '.join(i for i in rules[rules[wc_source].notnull()][wc_source].str.lower()))\n",
    "\n",
    "plt.figure(figsize=(16,9), dpi=wc_dpi)\n",
    "plt.axis('off')\n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g1XRVBkYAo_n"
   },
   "source": [
    "---\n",
    "## **Part 3. Integrations**\n",
    "Routines to export the data to other tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "4gxfwXwtKDDJ"
   },
   "outputs": [],
   "source": [
    "#@title Step 3a. MITRE Navigator Heatmap\n",
    "#@markdown Build and export a [MITRE Navigator](https://mitre-attack.github.io/attack-navigator/) layer based on the loaded rules.\n",
    "#\n",
    "#@markdown MITRE Navigator is a great tool to help you compare different scenarios expressed in layers.\n",
    "#@markdown One good example is to overlay the SIEM layer with another layer from CTI or related to any APT.\n",
    "#@markdown Having the two layers loaded in Navigator as SIEM (`a`) and the other (`b`), you can create a third layer based on these ones and use an expression like `min(5 - (b - a), 5)` to combine scores from both layers in this new one.\n",
    "#@markdown This overlay provides insightful ideas on strengths and weaknesses, helping to prioritize actions.\n",
    "\n",
    "# TODO:\n",
    "# The user should be able to select if he wants solid colors\n",
    "# (technique.color:hexcolor) or if he wants the color to be\n",
    "# an extra dimension like severity, priority, or detection_score.\n",
    "\n",
    "\n",
    "from copy import deepcopy\n",
    "from json import dump\n",
    "\n",
    "\n",
    "LAYER = 'chronicle-siem-map.json'  #@param{type:'string'}\n",
    "\n",
    "mitre_attack_version = '14'           #@param{type:'string'}\n",
    "mitre_navigator_version = '4.9.1'     #@param{type:'string'}\n",
    "mitre_navigator_layer_format = '4.5'  #@param{type:'string'}\n",
    "\n",
    "name = 'SIEM'               #@param{type:'string'}\n",
    "source = 'Chronicle SIEM'   #@param{type:'string'}\n",
    "description = 'SIEM Rules'  #@param{type:'string'}\n",
    "\n",
    "tactic_background = True      #@param['True','False']{type:'raw'}\n",
    "tactic_hexcolor = '820AD1FF'  #@param{type:'string'}\n",
    "\n",
    "technique_show_sub = False                       #@param['True','False']{type:'raw'}\n",
    "technique_comment = 'Chronicle SIEM assessment'  #@param{type:'string'}\n",
    "\n",
    "# static coloring (background color)\n",
    "technique_hexcolor = '008744FF'  #@param{type:'string'}\n",
    "\n",
    "# dynamic coloring (scores)\n",
    "gradient_color_1 = 'D62D20FF'  #@param{type:'string'}\n",
    "gradient_color_2 = 'FFA700FF'  #@param{type:'string'}\n",
    "gradient_color_3 = '008744FF'  #@param{type:'string'}\n",
    "gradient_min_value = 1         #@param{type:'integer'}\n",
    "gradient_max_value = 5         #@param{type:'integer'}\n",
    "\n",
    "# the layer template\n",
    "layer = {\n",
    "\t'name': name,\n",
    "\t'versions': {\n",
    "\t\t'attack': mitre_attack_version,\n",
    "\t\t'navigator': mitre_navigator_version,\n",
    "\t\t'layer': mitre_navigator_layer_format\n",
    "\t},\n",
    "\t'domain': 'enterprise-attack',\n",
    "\t'description': description,\n",
    "\t'showTacticRowBackground': tactic_background,\n",
    "\t'tacticRowBackground': f'#{tactic_hexcolor}',\n",
    "  'gradient': {\n",
    "\t  'colors': [\n",
    "\t\t\tf'#{gradient_color_1}',\n",
    "\t\t\tf'#{gradient_color_2}',\n",
    "\t\t\tf'#{gradient_color_3}'\n",
    "\t\t],\n",
    "\t\t\"minValue\": gradient_min_value,\n",
    "\t\t\"maxValue\": gradient_max_value\n",
    "\t},\n",
    "\t'techniques': []\n",
    "}\n",
    "\n",
    "# technique template\n",
    "template_technique = {\n",
    "    'techniqueID': '',\n",
    "    # 'color': f'#{technique_hexcolor}',  # test if we're gonna use gradient (scores) of fixed colors\n",
    "\t\t'score': 1,  # if dynamic, should be calculated based on extra dimension\n",
    "    'comment': technique_comment,\n",
    "    'metadata': [],\n",
    "    'links': [],\n",
    "    'enabled': True,\n",
    "    'showSubtechniques': technique_show_sub\n",
    "}\n",
    "\n",
    "mapping = {\n",
    "    'basic': 1,\n",
    "    'fair': 2,\n",
    "    'good': 3,\n",
    "    'very good': 4,\n",
    "    'excellent': 5\n",
    "  }\n",
    "\n",
    "def score_to_int(s):\n",
    "  try:\n",
    "    return mapping[s]\n",
    "  except KeyError:\n",
    "    return 0\n",
    "\n",
    "# filter rules with mitre.attack data, live, and alerting\n",
    "attack_rulez = rules[rules[['meta.mitre_technique']].notnull().all(1)]\n",
    "attack_rulez = attack_rulez[(attack_rulez['live'] == True) & (attack_rulez['alerting'] == True)]\n",
    "attack_rulez['meta.detection_score_int'] = attack_rulez['meta.detection_score'].apply(score_to_int)\n",
    "covered_techniques = sorted(set([i for ii in attack_rulez['meta.mitre_technique'].to_list() for i in ii]))\n",
    "techniques = list()\n",
    "\n",
    "for t in covered_techniques:\n",
    "\tfilter = attack_rulez[attack_rulez['meta.mitre_technique'].apply(lambda x: t in x)]\n",
    "\ttechnique = deepcopy(template_technique)\n",
    "\ttechnique['techniqueID'] = t\n",
    "\ttechnique['score'] = sum(filter['meta.detection_score_int'].to_list()) // len(filter['meta.detection_score_int'].to_list())\n",
    "\ttechnique['metadata'] = [{'name':'rule','value':x} for x in filter['name'].to_list()]\n",
    "\ttechnique['links'] = [{'label':'reference','url':x} for x in filter['meta.reference'].to_list()]\n",
    "\ttechniques.append(technique)\n",
    "\n",
    "layer['techniques'] = techniques\n",
    "\n",
    "with open(LAYER, 'w') as f:\n",
    "  dump(layer, f)\n",
    "files.download(LAYER)\n",
    "\n",
    "print('üü¢ Layer is ready to roll')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "WEYKI7rdKe5i"
   },
   "outputs": [],
   "source": [
    "#@title Step 3b. Export Rules in CSV\n",
    "OUT_FILE = 'chronicle-rules.csv' #@param{type:\"string\"}\n",
    "rules.to_csv(OUT_FILE, index=False)\n",
    "print(f'üü¢ {len(out_rules)} rules exported in {OUT_FILE} - the download should start soon...')\n",
    "files.download(OUT_FILE)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
